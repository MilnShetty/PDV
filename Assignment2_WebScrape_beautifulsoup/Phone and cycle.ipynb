{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup  \n",
    "from fake_useragent import UserAgent\n",
    "import csv\n",
    " \n",
    "user_agent = UserAgent()\n",
    " \n",
    "records = []  \n",
    " \n",
    "pages = [1,2,3,4]\n",
    "for page in pages:\n",
    "    page = requests.get(\"https://www.amazon.in/s?k=cycle&page=3&ref=sr_pg_\"+str(page),headers={'user-agent':user_agent.chrome})\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')  \n",
    "    results = soup.find_all('div', attrs={'class':'a-section a-spacing-small a-spacing-top-small'})\n",
    "    for result in results:  \n",
    "        name = result.find('span', attrs={'class':'a-size-medium a-color-base a-text-normal'})\n",
    "        price=result.find('span',attrs={'class':'a-price-whole'})\n",
    "        if name is not None and price is not None:\n",
    "            detail={}\n",
    "            detail['name'] = name.text\n",
    "            detail['price'] = price.text\n",
    "            records.append(detail)\n",
    " \n",
    "filename = 'a.csv'\n",
    "with open(filename, 'w', newline='') as f:\n",
    "    w = csv.DictWriter(f,['name','price'])\n",
    "    w.writeheader()\n",
    "    for detail in records:\n",
    "     w.writerow(detail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data from page 1...\n",
      "Scraping data from page 2...\n",
      "Scraping data from page 3...\n",
      "Scraping data from page 4...\n",
      "Scraping data from page 5...\n",
      "Data has been saved to 'f.csv'\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "from fake_useragent import UserAgent  # Import the UserAgent class\n",
    "\n",
    "# List to store iPhone information\n",
    "iPhones = []\n",
    "\n",
    "# Function to scrape iPhone details from a single page\n",
    "def scrape_page(url):\n",
    "    user_agent = UserAgent()  # Create a UserAgent object to generate random user-agents\n",
    "    headers = {'User-Agent': user_agent.random}  # Get a random user-agent\n",
    "\n",
    "    response = requests.get(url, headers=headers)  # Use the random user-agent in the request\n",
    "    \n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    for product in soup.find_all('div', class_='s-result-item'):\n",
    "        name_element = product.find('span', class_='a-text-normal')\n",
    "        rate_element = product.find('span', class_='a-price-whole')\n",
    "        rating_element = product.find('i', class_='a-icon-star-small')\n",
    "\n",
    "        if name_element and rate_element and rating_element:\n",
    "            name_text = name_element.get_text()\n",
    "            rate_text = rate_element.get_text()\n",
    "            rating_text = rating_element.find_next('span', class_='a-icon-alt').get_text()\n",
    "\n",
    "            iPhones.append([name_text, rate_text, rating_text])\n",
    "\n",
    "# URL of the Amazon search results page for 'iphone'\n",
    "base_url = 'https://www.amazon.in/s?k=phone&page=2&crid=3JBAX1EW5RVK5&qid=1698369102&sprefix=phone%2Caps%2C272&ref=sr_pg_1'\n",
    "\n",
    "# Number of pages to scrape (you can adjust this as needed)\n",
    "num_pages = 5\n",
    "\n",
    "# Loop through pages\n",
    "for page in range(1, num_pages + 1):\n",
    "    url = f'{base_url}&page={page}'\n",
    "    print(f\"Scraping data from page {page}...\")\n",
    "    scrape_page(url)\n",
    "\n",
    "# Create a CSV file and write iPhone data\n",
    "with open('f.csv', 'w', newline='') as csv_file:\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "    csv_writer.writerow(['Name', 'Rate', 'Rating'])\n",
    "    csv_writer.writerows(iPhones)\n",
    "\n",
    "print(\"Data has been saved to 'f.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pycaretenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
