{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrape data contents navigating  through multiple web page using Beautiful soup library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import BeautifulSoup for parsing HTML content\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Import the requests module for making HTTP GET requests\n",
    "import requests\n",
    "\n",
    "# Import the csv module for working with CSV files\n",
    "import csv\n",
    "\n",
    "# Import pandas for data manipulation and analysis\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# List to store book information\n",
    "Books = []\n",
    "\n",
    "# Loop through pages 1 to 50\n",
    "for i in range(1, 5):\n",
    "    url = f'https://books.toscrape.com/catalogue/page-{i}.html'\n",
    "    \n",
    "    # Send a GET request to the webpage\n",
    "    response = requests.get(url)\n",
    "    response = response.content\n",
    "    \n",
    "    # Create a BeautifulSoup object to parse the HTML content\n",
    "    soup = BeautifulSoup(response, 'lxml')\n",
    "    \n",
    "    # Find the <ol> element containing book articles\n",
    "    ol = soup.find('ol')\n",
    "    \n",
    "    # Find all book articles within the <ol>\n",
    "    articles = ol.find_all('article', class_='product_pod')\n",
    "\n",
    "    # Loop through each book article\n",
    "    for article in articles:\n",
    "        # Extract book title from the 'alt' attribute of the image\n",
    "        image = article.find('img')\n",
    "        title = image.attrs['alt']\n",
    "        \n",
    "        # Extract star rating from the 'class' attribute of the <p> element\n",
    "        star = article.find('p')\n",
    "        star = star['class'][1]\n",
    "        \n",
    "        # Extract book price\n",
    "        price = article.find('p', class_='price_color').get_text()\n",
    "        price = float(price[1:])\n",
    "        \n",
    "        # Append book information to the list\n",
    "        Books.append([title, price, star])\n",
    "\n",
    "# The 'Books' list now contains book information for all pages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame from the 'Books' list\n",
    "# The list 'Books' should contain book information in the format [title, price, star]\n",
    "df = pd.DataFrame(Books, columns= ['Title','price','star'])\n",
    "\n",
    "# Save the DataFrame to a CSV file named 'bookssss.csv'\n",
    "df.to_csv('book.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pycaretenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
