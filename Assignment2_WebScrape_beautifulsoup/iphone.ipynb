{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data from page 1...\n",
      "Scraping data from page 2...\n",
      "Scraping data from page 3...\n",
      "Scraping data from page 4...\n",
      "Scraping data from page 5...\n",
      "Data has been saved to 'iphone_data_with_fake_ua.csv'\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "from fake_useragent import UserAgent  # Import the UserAgent class\n",
    "\n",
    "# List to store iPhone information\n",
    "iPhones = []\n",
    "\n",
    "# Function to scrape iPhone details from a single page\n",
    "def scrape_page(url):\n",
    "    user_agent = UserAgent()  # Create a UserAgent object to generate random user-agents\n",
    "    headers = {'User-Agent': user_agent.random}  # Get a random user-agent\n",
    "\n",
    "    response = requests.get(url, headers=headers)  # Use the random user-agent in the request\n",
    "    response.raise_for_status()\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    for product in soup.find_all('div', class_='s-result-item'):\n",
    "        name_element = product.find('span', class_='a-text-normal')\n",
    "        rate_element = product.find('span', class_='a-price-whole')\n",
    "        rating_element = product.find('i', class_='a-icon-star-small')\n",
    "\n",
    "        if name_element and rate_element and rating_element:\n",
    "            name_text = name_element.get_text()\n",
    "            rate_text = rate_element.get_text()\n",
    "            rating_text = rating_element.find_next('span', class_='a-icon-alt').get_text()\n",
    "\n",
    "            iPhones.append([name_text, rate_text, rating_text])\n",
    "\n",
    "# URL of the Amazon search results page for 'iphone'\n",
    "base_url = 'https://www.amazon.in/s?k=iphone&crid=1YZ83GFU7AOZU&sprefix=ip%2%2C267&ref=nb_sb_ss_ts-doa-p_1_2'\n",
    "\n",
    "# Number of pages to scrape (you can adjust this as needed)\n",
    "num_pages = 5\n",
    "\n",
    "# Loop through pages\n",
    "for page in range(1, num_pages + 1):\n",
    "    url = f'{base_url}&page={page}'\n",
    "    print(f\"Scraping data from page {page}...\")\n",
    "    scrape_page(url)\n",
    "\n",
    "# Create a CSV file and write iPhone data\n",
    "with open('iphone_data_with_fake_ua.csv', 'w', newline='') as csv_file:\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "    csv_writer.writerow(['Name', 'Rate', 'Rating'])\n",
    "    csv_writer.writerows(iPhones)\n",
    "\n",
    "print(\"Data has been saved to 'iphone_data_with_fake_ua.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from fake_useragent import UserAgent\n",
    "import csv\n",
    "\n",
    "# Create a UserAgent object to generate random user-agents\n",
    "user_agent = UserAgent()\n",
    "\n",
    "# Initialize an empty list to store records\n",
    "records = []\n",
    "\n",
    "# Define a list of page numbers to scrape\n",
    "pages = [1, 2, 3, 4]\n",
    "\n",
    "# Loop through each page number\n",
    "for page in pages:\n",
    "    # Construct the URL for the Amazon search results page with the specific page number\n",
    "    url = \"https://www.amazon.in/s?k=samsung&i=electronics&rh=n%3A1805560031&page=2&qid=1698321956&ref=sr_pg_\" + str(page)\n",
    "    \n",
    "    # Send an HTTP GET request to the URL with a random user-agent\n",
    "    page = requests.get(url, headers={'user-agent': user_agent.chrome})\n",
    "    \n",
    "    # Create a BeautifulSoup object to parse the HTML content of the page\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "    \n",
    "    # Find all div elements with a specific class\n",
    "    results = soup.find_all('div', attrs={'class': 'a-section a-spacing-none a-spacing-top-small s-title-instructions-style'})\n",
    "    \n",
    "    # Loop through the results\n",
    "    for result in results:\n",
    "        name_element = result.find('span', attrs={'class': 'a-size-base-plus a-color-base a-text-normal'})\n",
    "        rate_element = result.find('span', attrs={'class': 'a-price-whole'})\n",
    "        rating_element = result.find('span', attrs={'class': 'a-icon-alt'})\n",
    "\n",
    "        if name_element:\n",
    "            name = name_element.text\n",
    "        else:\n",
    "            name = \"Name not found\"\n",
    "\n",
    "        if rate_element:\n",
    "            rate = rate_element.text\n",
    "        else:\n",
    "            rate = \"Rate not found\"\n",
    "\n",
    "        if rating_element:\n",
    "            rating = rating_element.text\n",
    "        else:\n",
    "            rating = \"Rating not found\"\n",
    "\n",
    "        # Append the extracted data to the records list\n",
    "        records.append([name, rate, rating])\n",
    "\n",
    "# Define the CSV file name\n",
    "csv_file_name = 'amazon_samsung_products1.csv'\n",
    "\n",
    "# Write records to a CSV file\n",
    "with open(csv_file_name, 'w', newline='', encoding='utf-8') as csv_file:\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "    \n",
    "    # Write the header row (if needed)\n",
    "    # csv_writer.writerow(['Product Name'])  # Uncomment this line if you want a header row\n",
    "    \n",
    "    # Write the records to the CSV file\n",
    "    csv_writer.writerows(records)\n",
    "\n",
    "print(f\"Data has been saved to '{csv_file_name}'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pycaretenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
